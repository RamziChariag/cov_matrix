{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misspecified MC Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MC_functions as mc\n",
    "import numpy as np\n",
    "from scipy import dot\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_t\n",
    "from scipy.linalg import eigh\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.numpy2ri\n",
    "import multiprocessing as mp\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "number_of_variables = 1\n",
    "w = 2\n",
    "beta = np.array([2]) # in the multivariate case, just add elements until the size of the vector is equal to number_of_variables\n",
    "N1 = 8\n",
    "N2 = 7\n",
    "T = 6\n",
    "n = N1 * N2 * T\n",
    "case = 3 # correspond to the three cases of omega in the chapter\n",
    "mu_epsilon = 0\n",
    "sigma_epsilon = 8\n",
    "non_zero_prob = 0.6\n",
    "mu_x = 0\n",
    "sigma_x = 1\n",
    "mu_z = 0\n",
    "sigma_z = 1\n",
    "mu_d = 0\n",
    "sigma_d = 1\n",
    "mu_v = 0\n",
    "sigma_v = 5\n",
    "mu_z = 0\n",
    "sigma_z = 5\n",
    "specification = \"normal\" # \"normal\", \"t\" or \"sn\"\n",
    "mu_e = 0\n",
    "mu_e_vec= np.full(n, mu_e)\n",
    "sigma_e = 1\n",
    "t_dist_degree = 5\n",
    "mu_U = 0\n",
    "\n",
    "# Define the block dimensions\n",
    "if case ==2:\n",
    "    block_size = N2  # Adjust this to your specific block size\n",
    "elif case == 3:\n",
    "    block_size = T\n",
    "\n",
    "# Determine the total number of blocks\n",
    "num_blocks = n // block_size\n",
    "\n",
    "# spcov parameters\n",
    "lambda_parameter = 2\n",
    "spcov = importr(\"spcov\")\n",
    "max_penalty = 1\n",
    "ksi_1 = 12  # controls the smallest penalty, the higher the value the smaller \n",
    "ksi_2 = 1.5   # flattening parameter for sigmoid penalty function\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# for computational reasons, we have to add a term eta to the diagonal, and also set small values that are close to zero to actual zero, because those are due to numerical errors\n",
    "eta = 1e-5\n",
    "tolerance = 1e-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy2.robjects.numpy2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the R context for each thread or process\n",
    "def initialize_r_context():\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects.packages import importr\n",
    "    import rpy2.robjects.numpy2ri\n",
    "    \n",
    "    # Activate numpy2ri conversion within the local R context\n",
    "    rpy2.robjects.numpy2ri.activate()    \n",
    "    spcov = importr(\"spcov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.normal(-2, 1, (N1*N2, 1))\n",
    "z = np.tile(z, (T, 1))\n",
    "d = np.random.normal(mu_d, sigma_d, (n, number_of_variables))\n",
    "x = z + d\n",
    "v = np.random.normal(mu_v, sigma_v, (n, 1))\n",
    "g = w * z + v\n",
    "disturbances = np.random.normal(mu_e, sigma_e, (n, 1))\n",
    "y = np.dot(x, beta) + g.flatten() + disturbances.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MM converged in 3 steps!\n",
      "MM converged in 2 steps!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate three fixed-effect variables\n",
    "fixed_effect_1 = np.random.normal(-2, 1, (N1, 1))\n",
    "fixed_effect_2 = np.random.normal(3, 1, (N2, 1))\n",
    "fixed_effect_3 = np.random.normal(1, 1, (T, 1))\n",
    "z = np.random.normal(mu_z, sigma_z, (N1*N2, 1))\n",
    "\n",
    "# Step 2: Repeat the fixed-effect variables to match the desired dimensions\n",
    "fixed_effect_1 = np.repeat(fixed_effect_1, N2 * T, axis=0)\n",
    "fixed_effect_2 = np.tile(fixed_effect_2, (N1 * T, 1))\n",
    "fixed_effect_3 = np.tile(fixed_effect_3, (N1 * N2, 1))\n",
    "z = np.tile(z, (T, 1))\n",
    "\n",
    "# Step 3: Stack the fixed-effect variables and combine x and fixed effects\n",
    "fixed_effects_matrix = np.hstack((fixed_effect_1, fixed_effect_2, fixed_effect_3))\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Generate x\n",
    "d = np.random.normal(mu_d, sigma_d, (n, number_of_variables))\n",
    "x = z + d\n",
    "v = np.random.normal(mu_v, sigma_v, (n, 1))\n",
    "g = w * z + v\n",
    "\n",
    "X = np.hstack((x, fixed_effects_matrix))\n",
    "\n",
    "\n",
    "# Step 5: generate distrubances using the covariance matrix\n",
    "#omega = mc.generate_omega(case, mu_e, sigma_e, non_zero_prob, N1, N2, T, seed)\n",
    "#disturbances = mc.generate_disturbances(mu_e_vec, omega, n, t_dist_degree, lambda_parameter, mu_U, specification, seed)\n",
    "disturbances = np.random.normal(mu_e, sigma_e, (n, 1))\n",
    "\n",
    "# Step 6: Generate y using linear relationship: y = X * beta + FE + disturbances\n",
    "#y = np.dot(x, beta) + fixed_effects_matrix.sum(axis=1) + disturbances.flatten()\n",
    "y = np.dot(x, beta) + g.flatten() + disturbances.flatten()\n",
    "\n",
    "# Step 7: Transform X and y\n",
    "x_tilde, y_tilde = mc.transform_xy(X, y,number_of_variables)\n",
    "X = np.hstack((x_tilde, fixed_effects_matrix))\n",
    "y = y_tilde\n",
    "\n",
    "# Step 8: Estimate beta using OLS formula\n",
    "X_with_intercept = np.hstack((np.ones((n, 1)), X))  # Adding intercept term\n",
    "X_transpose = np.transpose(X_with_intercept)\n",
    "X_transpose_X_inv = np.linalg.inv(np.dot(X_transpose, X_with_intercept))\n",
    "beta_hat = np.dot(np.dot(X_transpose_X_inv, X_transpose), y)\n",
    "\n",
    "# Step 9: Calculate the variance-covariance matrix of beta_hat\n",
    "# OLS\n",
    "epsilon_hat = y - np.dot(X_with_intercept, beta_hat)\n",
    "omega_hat = np.dot(epsilon_hat, epsilon_hat)/(n-number_of_variables-4)\n",
    "sigma_hat = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "# robust\n",
    "omega_hat_robust = np.outer(epsilon_hat, epsilon_hat)\n",
    "omega_hat_robust = np.eye(omega_hat_robust.shape[0]) * omega_hat_robust\n",
    "sigma_hat_robust = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_robust), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "# spcov\n",
    "# Initialize an empty omega_hat matrix\n",
    "omega_hat_spcov = np.zeros((n, n))\n",
    "S_mat_full = np.outer(epsilon_hat, epsilon_hat)\n",
    "block_omega_hat_spcov_list = []\n",
    "\n",
    "# Extract blocks\n",
    "init_omega_blocks = mc.extract_blocks(omega_hat_robust, block_size)\n",
    "S_mat_blocks = mc.extract_blocks(S_mat_full, block_size)\n",
    "\n",
    "# Loop through the blocks\n",
    "for block in range(len(init_omega_blocks)):\n",
    "    # Extract the current block\n",
    "    init_omega = init_omega_blocks[block]\n",
    "    S_mat = S_mat_blocks[block]\n",
    "    S_mat = mc.make_positive_definite(S_mat)\n",
    "    \n",
    "    # spcov\n",
    "    Lambda = mc.generate_penalty_matrix(max_penalty, block_size, ksi_1, ksi_2)\n",
    "    init_omega_r = ro.r.matrix(init_omega, nrow=block_size, ncol=block_size)\n",
    "    S_r = ro.r.matrix(S_mat, nrow=block_size, ncol=block_size)\n",
    "    Lambda_r = ro.r.matrix(Lambda, nrow=block_size, ncol=block_size)\n",
    "    spcov_result = spcov.spcov(\n",
    "        init_omega_r,\n",
    "        S_r,\n",
    "        Lambda_r,\n",
    "        step_size=0.1,\n",
    "        nesterov=True,\n",
    "        n_outer_steps=30,\n",
    "        n_inner_steps=30,\n",
    "        tol_outer=1e-04,\n",
    "        thr_inner=0.01,\n",
    "        backtracking=0.2,\n",
    "        trace=0\n",
    "    )\n",
    "    \n",
    "    # Append the estimated block to the list\n",
    "    block_omega_hat_spcov_list.append(spcov_result[1])\n",
    "\n",
    "# Calculate the average block_omega_hat_spcov\n",
    "average_block_omega_hat_spcov = np.mean(block_omega_hat_spcov_list, axis=0)\n",
    "\n",
    "# Fill the entire omega_hat_spcov matrix with the average block\n",
    "for block in range(len(init_omega_blocks)):\n",
    "    row_start = block * block_size\n",
    "    row_end = (block + 1) * block_size\n",
    "    col_start = block * block_size\n",
    "    col_end = (block + 1) * block_size\n",
    "    omega_hat_spcov[row_start:row_end, col_start:col_end] = average_block_omega_hat_spcov\n",
    "\n",
    "\n",
    "sigma_hat_spcov = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_spcov), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "# Ledoit and Wolf (2004): \n",
    "# Initialize an empty omega_hat matrix\n",
    "omega_hat_shrinkage = np.zeros((n, n))\n",
    "\n",
    "# S_mat_full = mc.make_positive_definite_2(np.outer(epsilon_hat, epsilon_hat), eta)\n",
    "S_mat_full = np.outer(epsilon_hat, epsilon_hat)\n",
    "\n",
    "# Extract blocks\n",
    "S_mat_blocks = mc.extract_blocks(S_mat_full, block_size)\n",
    "\n",
    "# Calculate the average S_mat from the list S_mat_blocks\n",
    "avg_S_mat = np.mean(S_mat_blocks, axis=0)\n",
    "\n",
    "# Extract subvectors of size T from epsilon_hat\n",
    "epsilon_hats = [epsilon_hat[i:i+T] for i in range(0, n, T)]\n",
    "\n",
    "# Create a matrix from the vectors in epsilon_hats where each vector is a row\n",
    "epsilon_hat_matrix = np.vstack(epsilon_hats)\n",
    "\n",
    "avg_S_mat = mc.zero_elements_below_tolerance(avg_S_mat, tolerance)\n",
    "avg_S_mat = mc.make_positive_definite_2(avg_S_mat, eta)\n",
    "mu_parameter = mc.braket_operator_identity(avg_S_mat)\n",
    "delta_parameter = mc.scaled_f_norm(avg_S_mat - mu_parameter * np.eye(block_size))**2\n",
    "beta_tilde = mc.f_norm_variance(epsilon_hat_matrix, avg_S_mat)\n",
    "beta_parameter = min(beta_tilde, delta_parameter)\n",
    "gamma_star = beta_parameter / delta_parameter\n",
    "\n",
    "avg_omega_hat_shrinkage_block = gamma_star * mu_parameter * np.eye(block_size) + (1 - gamma_star) * avg_S_mat\n",
    "# Fill the diagonal blocks of omega_hat_shrinkage with omega_hat_shrinkage_block\n",
    "for i in range(num_blocks):\n",
    "    row_start = i * block_size\n",
    "    row_end = (i + 1) * block_size\n",
    "    col_start = i * block_size\n",
    "    col_end = (i + 1) * block_size\n",
    "    omega_hat_shrinkage[row_start:row_end, col_start:col_end] = avg_omega_hat_shrinkage_block\n",
    "sigma_hat_shrinkage = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_shrinkage), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "# Step 10: Construct the t-statistics for beta_hat\n",
    "t_stat_robust = beta_hat / np.sqrt(np.diag(sigma_hat_robust))\n",
    "t_stat_spcov = beta_hat / np.sqrt(np.diag(sigma_hat_spcov))\n",
    "t_stat_shrinkage = beta_hat / np.sqrt(np.diag(sigma_hat_shrinkage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_spcov(i, ksi_2):\n",
    "    # Initialize R context for this thread or process\n",
    "    initialize_r_context()\n",
    "    print(f\"Iteration {i + 1} started...\")\n",
    "    try: \n",
    "        # Step 1: Generate three fixed-effect variables\n",
    "        fixed_effect_1 = np.random.normal(-2, 1, (N1, 1))\n",
    "        fixed_effect_2 = np.random.normal(3, 1, (N2, 1))\n",
    "        fixed_effect_3 = np.random.normal(1, 1, (T, 1))\n",
    "        z = np.random.normal(mu_z, sigma_z, (N1*N2, 1))\n",
    "\n",
    "        # Step 2: Repeat the fixed-effect variables to match the desired dimensions\n",
    "        fixed_effect_1 = np.repeat(fixed_effect_1, N2 * T, axis=0)\n",
    "        fixed_effect_2 = np.tile(fixed_effect_2, (N1 * T, 1))\n",
    "        fixed_effect_3 = np.tile(fixed_effect_3, (N1 * N2, 1))\n",
    "        z = np.tile(z, (T, 1))\n",
    "\n",
    "        # Step 3: Stack the fixed-effect variables \n",
    "        fixed_effects_matrix = np.hstack((fixed_effect_1, fixed_effect_2, fixed_effect_3))\n",
    "      \n",
    "\n",
    "\n",
    "        # Step 4: Generate x\n",
    "        d = np.random.normal(mu_d, sigma_d, (n, number_of_variables))\n",
    "        x = z + d\n",
    "        v = np.random.normal(mu_v, sigma_v, (n, 1))\n",
    "        g = w * z + v\n",
    "\n",
    "        X = np.hstack((x, fixed_effects_matrix))\n",
    "\n",
    "        # Step 5: generate distrubances using the covariance matrix\n",
    "        #omega = mc.generate_omega(case, mu_e, sigma_e, non_zero_prob, N1, N2, T, seed)\n",
    "        #disturbances = mc.generate_disturbances(mu_e_vec, omega, n, t_dist_degree, lambda_parameter, mu_U, specification, seed)\n",
    "        disturbances = np.random.normal(mu_e, sigma_e, (n, 1))\n",
    "\n",
    "        # Step 6: Generate y using linear relationship: y = X * beta + FE + disturbances\n",
    "        #y = np.dot(x, beta) + fixed_effects_matrix.sum(axis=1) + disturbances.flatten()\n",
    "        y = np.dot(x, beta) + g.flatten() + disturbances.flatten()\n",
    "\n",
    "        # Step 7: Transform X and y\n",
    "        x_tilde, y_tilde = mc.transform_xy(X, y,number_of_variables)\n",
    "        X = np.hstack((x_tilde, fixed_effects_matrix))\n",
    "        y = y_tilde\n",
    "\n",
    "        # Step 8: Estimate beta using OLS formula\n",
    "        X_with_intercept = np.hstack((np.ones((n, 1)), X))  # Adding intercept term\n",
    "        X_transpose = np.transpose(X_with_intercept)\n",
    "        X_transpose_X_inv = np.linalg.inv(np.dot(X_transpose, X_with_intercept))\n",
    "        beta_hat = np.dot(np.dot(X_transpose_X_inv, X_transpose), y)\n",
    "\n",
    "        # Step 9: Calculate the variance-covariance matrix of beta_hat\n",
    "\n",
    "        #Robust\n",
    "        omega_hat_robust = np.outer(epsilon_hat, epsilon_hat)\n",
    "        omega_hat_robust = np.eye(omega_hat_robust.shape[0]) * omega_hat_robust\n",
    "\n",
    "        #spcov\n",
    "        init_omega = omega_hat_robust\n",
    "        Lambda = mc.generate_penalty_matrix(max_penalty, n, ksi_1,ksi_2)\n",
    "        S_mat = mc.make_positive_definite(np.outer(epsilon_hat, epsilon_hat))\n",
    "        init_omega_r = ro.r.matrix(init_omega, nrow=n, ncol=n)\n",
    "        S_r = ro.r.matrix(S_mat, nrow=n, ncol=n)\n",
    "        Lambda_r = ro.r.matrix(Lambda, nrow=n, ncol=n)\n",
    "        spcov_result = spcov.spcov(\n",
    "        init_omega_r,\n",
    "        S_r,\n",
    "        Lambda_r,\n",
    "        step_size=0.1,\n",
    "        nesterov = True,\n",
    "        n_outer_steps = 800,\n",
    "        n_inner_steps = 800,\n",
    "        tol_outer = 1e-04,\n",
    "        thr_inner = 0.01,\n",
    "        backtracking = 0.2,\n",
    "        trace = 0\n",
    "        )\n",
    "\n",
    "        omega_hat_spcov = spcov_result[1]\n",
    "        sigma_hat_spcov = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_spcov), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "        # Step 10: Construct the t-statistics for beta_hat\n",
    "        t_stat_spcov = beta_hat / np.sqrt(np.diag(sigma_hat_spcov))\n",
    "\n",
    "        # Step 11: Calculate the RMSE\n",
    "        spcov_rmse = np.sqrt(np.sum(np.square(omega_hat_spcov - omega)) / (n * n))  \n",
    "\n",
    "        print(f\"Iteration {i + 1} completed.\")\n",
    "\n",
    "        # Clean up resources explicitly\n",
    "        del x, fixed_effect_1, fixed_effect_2, fixed_effect_3, fixed_effects_matrix\n",
    "        del X, omega, disturbances, x_tilde, y_tilde, X_with_intercept\n",
    "        del init_omega, Lambda, S_mat, init_omega_r, S_r, Lambda_r, spcov_result\n",
    "        del omega_hat_spcov, sigma_hat_spcov, omega_hat_robust\n",
    "        # Trigger Python's garbage collector to release memory\n",
    "        gc.collect()\n",
    "        \n",
    "        return beta_hat, t_stat_spcov, spcov_rmse, ksi_2\n",
    "    finally:\n",
    "        # Close the local R context\n",
    "        ro.r(\"gc()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to store results\n",
    "all_t_stat_spcov = []\n",
    "all_spcov_rmse = []\n",
    "\n",
    "# Define loop parameters\n",
    "num_processes = mp.cpu_count()  # Number of processes to run in parallel\n",
    "tuning_range = np.arange(0.5, 4, 0.2)  # Range of penalty values to cross-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SexpCapsule.__del__ at 0x12f18aa70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ramzi.chariag/anaconda3/lib/python3.10/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\", line 150, in __del__\n",
      "    raise e\n",
      "  File \"/Users/ramzi.chariag/anaconda3/lib/python3.10/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\", line 142, in __del__\n",
      "    _release(self._cdata)\n",
      "  File \"/Users/ramzi.chariag/anaconda3/lib/python3.10/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\", line 70, in _release\n",
      "    count = _R_PRESERVED[addr] - 1\n",
      "KeyError: 5362077016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 started...\n",
      "Iteration 2 started...\n",
      "Iteration 5 started...\n",
      "Iteration 1 started...\n",
      "Iteration 7 started...\n",
      "Iteration 10 started...\n",
      "Iteration 4 started...\n",
      "Iteration 9 started...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create a thread pool executor\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_processes) as executor:\n",
    "        # Use a list comprehension to submit tasks to the thread pool\n",
    "        futures = [executor.submit(tune_spcov, i, ksi_2) for i, ksi_2 in enumerate(tuning_range)]\n",
    "        \n",
    "        # Retrieve results as they become available\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "    \n",
    "# Convert the results list to arrays\n",
    "all_spcov_rmse = np.array([result[2] for result in results])\n",
    "all_ksi_2 = np.array([result[3] for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'ksi_2': all_ksi_2, 'spcov_rmse': all_spcov_rmse})\n",
    "\n",
    "# Sort the DataFrame by ksi_2\n",
    "df = df.sort_values(by='ksi_2')\n",
    "\n",
    "# Find the row with the minimum spcov_rmse\n",
    "optimal_row = df[df['spcov_rmse'] == df['spcov_rmse'].min()]\n",
    "\n",
    "# Extract the optimal ksi_2 value\n",
    "optimal_ksi_2 = optimal_row['ksi_2'].values[0]\n",
    "\n",
    "# Plot ksi_2 vs. spcov_rmse\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(df['ksi_2'], df['spcov_rmse'], marker='o', linestyle='-')\n",
    "plt.xlabel('ksi_2')\n",
    "plt.ylabel('spcov_rmse')\n",
    "plt.title('ksi_2 Tuning')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(i):\n",
    "    # Initialize R context for this thread or process\n",
    "    initialize_r_context()\n",
    "    print(f\"Iteration {i + 1} started...\")\n",
    "    try: \n",
    "        # Step 1: Generate three fixed-effect variables\n",
    "        fixed_effect_1 = np.random.normal(-2, 1, (N1, 1))\n",
    "        fixed_effect_2 = np.random.normal(3, 1, (N2, 1))\n",
    "        fixed_effect_3 = np.random.normal(1, 1, (T, 1))\n",
    "        z = np.random.normal(mu_z, sigma_z, (N1*N2, 1))\n",
    "\n",
    "        # Step 2: Repeat the fixed-effect variables to match the desired dimensions\n",
    "        fixed_effect_1 = np.repeat(fixed_effect_1, N2 * T, axis=0)\n",
    "        fixed_effect_2 = np.tile(fixed_effect_2, (N1 * T, 1))\n",
    "        fixed_effect_3 = np.tile(fixed_effect_3, (N1 * N2, 1))\n",
    "        z = np.tile(z, (T, 1))\n",
    "\n",
    "        # Step 3: Stack the fixed-effect variables \n",
    "        fixed_effects_matrix = np.hstack((fixed_effect_1, fixed_effect_2, fixed_effect_3))\n",
    "      \n",
    "\n",
    "\n",
    "        # Step 4: Generate x\n",
    "        d = np.random.normal(mu_d, sigma_d, (n, number_of_variables))\n",
    "        x = z + d\n",
    "        v = np.random.normal(mu_v, sigma_v, (n, 1))\n",
    "        g = w * z + v\n",
    "\n",
    "        X = np.hstack((x, fixed_effects_matrix))\n",
    "\n",
    "        # Step 5: generate distrubances using the covariance matrix\n",
    "        #omega = mc.generate_omega(case, mu_e, sigma_e, non_zero_prob, N1, N2, T, seed)\n",
    "        #disturbances = mc.generate_disturbances(mu_e_vec, omega, n, t_dist_degree, lambda_parameter, mu_U, specification, seed)\n",
    "        disturbances = np.random.normal(mu_e, sigma_e, (n, 1))\n",
    "\n",
    "        # Step 6: Generate y using linear relationship: y = X * beta + FE + disturbances\n",
    "        #y = np.dot(x, beta) + fixed_effects_matrix.sum(axis=1) + disturbances.flatten()\n",
    "        y = np.dot(x, beta) + g.flatten() + disturbances.flatten()\n",
    "\n",
    "        # Step 7: Transform X and y\n",
    "        x_tilde, y_tilde = mc.transform_xy(X, y,number_of_variables)\n",
    "        X = np.hstack((x_tilde, fixed_effects_matrix))\n",
    "        y = y_tilde\n",
    "\n",
    "        # Step 8: Estimate beta using OLS formula\n",
    "        X_with_intercept = np.hstack((np.ones((n, 1)), X))  # Adding intercept term\n",
    "        X_transpose = np.transpose(X_with_intercept)\n",
    "        X_transpose_X_inv = np.linalg.inv(np.dot(X_transpose, X_with_intercept))\n",
    "        beta_hat = np.dot(np.dot(X_transpose_X_inv, X_transpose), y)\n",
    "\n",
    "        # Step 9: Calculate the variance-covariance matrix of beta_hat\n",
    "\n",
    "        #OLS\n",
    "        epsilon_hat = y - np.dot(X_with_intercept, beta_hat)\n",
    "        omega_hat_ols = np.dot(epsilon_hat, epsilon_hat)/(n-number_of_variables-4)\n",
    "        sigma_hat_ols = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_ols), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "        #Robust\n",
    "        omega_hat_robust = np.outer(epsilon_hat, epsilon_hat)\n",
    "        omega_hat_robust = np.eye(omega_hat_robust.shape[0]) * omega_hat_robust\n",
    "        sigma_hat_robust = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_robust), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "        #spcov\n",
    "        init_omega = omega_hat_robust\n",
    "        Lambda = mc.generate_penalty_matrix(max_penalty, n, ksi_1,ksi_2)\n",
    "        S_mat = mc.make_positive_definite(np.outer(epsilon_hat, epsilon_hat))\n",
    "        init_omega_r = ro.r.matrix(init_omega, nrow=n, ncol=n)\n",
    "        S_r = ro.r.matrix(S_mat, nrow=n, ncol=n)\n",
    "        Lambda_r = ro.r.matrix(Lambda, nrow=n, ncol=n)\n",
    "        spcov_result = spcov.spcov(\n",
    "        init_omega_r,\n",
    "        S_r,\n",
    "        Lambda_r,\n",
    "        step_size=0.1,\n",
    "        nesterov = True,\n",
    "        n_outer_steps = 800,\n",
    "        n_inner_steps = 800,\n",
    "        tol_outer = 1e-04,\n",
    "        thr_inner = 0.01,\n",
    "        backtracking = 0.2,\n",
    "        trace = 0\n",
    "        )\n",
    "\n",
    "        omega_hat_spcov = spcov_result[1]\n",
    "        sigma_hat_spcov = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_spcov), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "        # Ledoit and Wolf (2004): \n",
    "        # Initialize an empty omega_hat matrix\n",
    "        omega_hat_shrinkage = np.zeros((n, n))\n",
    "\n",
    "        # S_mat_full = mc.make_positive_definite_2(np.outer(epsilon_hat, epsilon_hat), eta)\n",
    "        S_mat_full = np.outer(epsilon_hat, epsilon_hat)\n",
    "\n",
    "        # Extract blocks\n",
    "        S_mat_blocks = mc.extract_blocks(S_mat_full, block_size)\n",
    "\n",
    "        # Calculate the average S_mat from the list S_mat_blocks\n",
    "        avg_S_mat = np.mean(S_mat_blocks, axis=0)\n",
    "\n",
    "        # Extract subvectors of size T from epsilon_hat\n",
    "        epsilon_hats = [epsilon_hat[i:i+T] for i in range(0, n, T)]\n",
    "\n",
    "        # Create a matrix from the vectors in epsilon_hats where each vector is a row\n",
    "        epsilon_hat_matrix = np.vstack(epsilon_hats)\n",
    "\n",
    "        avg_S_mat = mc.zero_elements_below_tolerance(avg_S_mat, tolerance)\n",
    "        avg_S_mat = mc.make_positive_definite_2(avg_S_mat, eta)\n",
    "        mu_parameter = mc.braket_operator_identity(avg_S_mat)\n",
    "        delta_parameter = mc.scaled_f_norm(avg_S_mat - mu_parameter * np.eye(block_size))**2\n",
    "        beta_tilde = mc.f_norm_variance(epsilon_hat_matrix, avg_S_mat)\n",
    "        beta_parameter = min(beta_tilde, delta_parameter)\n",
    "        gamma_star = beta_parameter / delta_parameter\n",
    "\n",
    "        avg_omega_hat_shrinkage_block = gamma_star * mu_parameter * np.eye(block_size) + (1 - gamma_star) * avg_S_mat\n",
    "        # Fill the diagonal blocks of omega_hat_shrinkage with omega_hat_shrinkage_block\n",
    "        for i in range(num_blocks):\n",
    "            row_start = i * block_size\n",
    "            row_end = (i + 1) * block_size\n",
    "            col_start = i * block_size\n",
    "            col_end = (i + 1) * block_size\n",
    "            omega_hat_shrinkage[row_start:row_end, col_start:col_end] = avg_omega_hat_shrinkage_block\n",
    "\n",
    "        # Fill the diagonal blocks of omega_hat_shrinkage with omega_hat_shrinkage_block\n",
    "        sigma_hat_shrinkage = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_shrinkage), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "        # Step 10: Construct the t-statistics for beta_hat\n",
    "        t_stat_ols = beta_hat / np.sqrt(np.diag(sigma_hat_ols))\n",
    "        t_stat_robust = beta_hat / np.sqrt(np.diag(sigma_hat_robust))\n",
    "        t_stat_spcov = beta_hat / np.sqrt(np.diag(sigma_hat_spcov))\n",
    "        t_stat_shrinkage = beta_hat / np.sqrt(np.diag(sigma_hat_shrinkage))\n",
    "\n",
    "        print(f\"Iteration {i + 1} completed.\")\n",
    "\n",
    "        # Clean up resources explicitly\n",
    "        del x, fixed_effect_1, fixed_effect_2, fixed_effect_3, fixed_effects_matrix\n",
    "        del X, omega, disturbances, x_tilde, y_tilde, X_with_intercept\n",
    "        del epsilon_hat, omega_hat_ols, sigma_hat_ols, omega_hat_robust, sigma_hat_robust\n",
    "        del init_omega, Lambda, S_mat, init_omega_r, S_r, Lambda_r, spcov_result\n",
    "        del omega_hat_spcov, sigma_hat_spcov, mu_parameter, delta_parameter, beta_tilde\n",
    "        del beta_parameter, gamma_star, omega_hat_shrinkage, sigma_hat_shrinkage\n",
    "        # Trigger Python's garbage collector to release memory\n",
    "        gc.collect()\n",
    "        \n",
    "        return beta_hat, t_stat_ols, t_stat_robust, t_stat_spcov, t_stat_shrinkage\n",
    "    finally:\n",
    "        # Close the local R context\n",
    "        ro.r(\"gc()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to store results\n",
    "all_beta_hat = []\n",
    "all_t_stat_ols = []\n",
    "all_t_stat_robust = []\n",
    "all_t_stat_spcov = []\n",
    "all_t_stat_shrinkage = []\n",
    "\n",
    "# Assign optimal ksi_2 value\n",
    "ksi_2 = round(optimal_ksi_2, 2)\n",
    "#ksi_2 = 2   \n",
    "# Define loop parameters\n",
    "num_iterations = 30  # Number of iterations\n",
    "num_processes = mp.cpu_count()  # Number of processes to run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create a thread pool executor\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_processes-1) as executor:\n",
    "        # Use a list comprehension to submit tasks to the thread pool\n",
    "        futures = [executor.submit(run_iteration, i) for i in range(num_iterations)]\n",
    "        \n",
    "        # Retrieve results as they become available\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "    \n",
    "# Convert the results list to arrays\n",
    "all_beta_hat = np.array([result[0] for result in results])\n",
    "all_t_stat_ols = np.array([result[1] for result in results])\n",
    "all_t_stat_robust = np.array([result[2] for result in results])\n",
    "all_t_stat_spcov = np.array([result[3] for result in results])\n",
    "all_t_stat_shrinkage = np.array([result[4] for result in results])\n",
    "\n",
    "# Now you can analyze or summarize the results as needed\n",
    "average_beta_hat = np.mean(all_beta_hat, axis=0)\n",
    "average_t_stat_ols = np.mean(all_t_stat_ols, axis=0)\n",
    "average_t_stat_robust = np.mean(all_t_stat_robust, axis=0)\n",
    "average_t_stat_spcov = np.mean(all_t_stat_spcov, axis=0)\n",
    "average_t_stat_shrinkage = np.mean(all_t_stat_shrinkage, axis=0)\n",
    "\n",
    "print(\"Average beta_hat:\", average_beta_hat)\n",
    "print(\"Average t_stat_ols:\", average_t_stat_ols)\n",
    "print(\"Average t_stat_robust:\", average_t_stat_robust)\n",
    "print(\"Average t_stat_spcov:\", average_t_stat_spcov)\n",
    "print(\"Average t_stat_shrinkage:\", average_t_stat_shrinkage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
