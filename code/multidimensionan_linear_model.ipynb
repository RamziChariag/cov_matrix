{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MC_functions as mc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_t\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.numpy2ri\n",
    "import multiprocessing as mp\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important note: make sure rpy2 is version 3.5.1 or below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install rpy2==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "number_of_variables = 1\n",
    "beta = np.array([2]) # in the multivariate case, just add elements until the size of the vector is equal to number_of_variables\n",
    "N1 = 5\n",
    "N2 = 10\n",
    "T = 3\n",
    "n = N1 * N2 * T\n",
    "case = 2 # correspond to the three cases of omega in the chapter\n",
    "mu_epsilon = 0\n",
    "sigma_epsilon = 8\n",
    "non_zero_prob = 0.6\n",
    "mu_x = 0\n",
    "sigma_x = 1\n",
    "specification = \"normal\" # \"normal\", \"t\" or \"sn\"\n",
    "mu_e = 0\n",
    "mu_e_vec= np.full(n, mu_e)\n",
    "sigma_e = 1\n",
    "t_dist_degree = 5\n",
    "mu_U = 0\n",
    "lambda_parameter = 2\n",
    "spcov = importr(\"spcov\")\n",
    "ksi_1 = 18  # controls the smallest penalty, the higher the value the smaller \n",
    "ksi_2 = 5   # flattening parameter for sigmoid penalty function\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy2.robjects.numpy2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate x variables\n",
    "x = np.random.normal(mu_x, sigma_x, (n, number_of_variables))\n",
    "\n",
    "# Step 2: Generate three fixed-effect variables\n",
    "fixed_effect_1 = np.random.normal(-2, 1, (N1, 1))\n",
    "fixed_effect_2 = np.random.normal(3, 1, (N2, 1))\n",
    "fixed_effect_3 = np.random.normal(1, 1, (T, 1))\n",
    "\n",
    "# Step 3: Repeat the fixed-effect variables to match the desired dimensions\n",
    "fixed_effect_1 = np.repeat(fixed_effect_1, N2 * T, axis=0)\n",
    "fixed_effect_2 = np.tile(fixed_effect_2, (N1 * T, 1))\n",
    "fixed_effect_3 = np.tile(fixed_effect_3, (N1 * N2, 1))\n",
    "\n",
    "# Step 4: Stack the fixed-effect variables and combine x and fixed effects\n",
    "fixed_effects_matrix = np.hstack((fixed_effect_1, fixed_effect_2, fixed_effect_3))\n",
    "X = np.hstack((x, fixed_effects_matrix))\n",
    "\n",
    "# Step 5: generate distrubances using the covariance matrix\n",
    "omega = mc.generate_omega(case, mu_e, sigma_e, non_zero_prob, N1, N2, T, seed)\n",
    "disturbances = mc.generate_disturbances(mu_e_vec, omega, n, t_dist_degree, lambda_parameter, mu_U, specification, seed)\n",
    "\n",
    "# Step 6: Generate y using linear relationship: y = X * beta + FE + disturbances\n",
    "y = np.dot(x, beta) + fixed_effects_matrix.sum(axis=1) + disturbances.flatten()\n",
    "\n",
    "# Step 7: Transform X and y\n",
    "x_tilde, y_tilde = mc.transform_xy(X, y,number_of_variables)\n",
    "X = np.hstack((x_tilde, fixed_effects_matrix))\n",
    "y = y_tilde\n",
    "\n",
    "# Step 8: Estimate beta using OLS formula\n",
    "X_with_intercept = np.hstack((np.ones((n, 1)), X))  # Adding intercept term\n",
    "X_transpose = np.transpose(X_with_intercept)\n",
    "X_transpose_X_inv = np.linalg.inv(np.dot(X_transpose, X_with_intercept))\n",
    "beta_hat = np.dot(np.dot(X_transpose_X_inv, X_transpose), y)\n",
    "\n",
    "# Step 9: Calculate the variance-covariance matrix of beta_hat\n",
    "# OLS\n",
    "epsilon_hat = y - np.dot(X_with_intercept, beta_hat)\n",
    "omega_hat = np.dot(epsilon_hat, epsilon_hat)/(n-number_of_variables-4)\n",
    "sigma_hat = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "# robust\n",
    "omega_hat_robust = np.outer(epsilon_hat, epsilon_hat)\n",
    "omega_hat_robust = np.eye(omega_hat_robust.shape[0]) * omega_hat_robust\n",
    "sigma_hat_robust = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_robust), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "# spcov\n",
    "init_omega = omega_hat_robust\n",
    "Lambda = mc.generate_penalty_matrix(n, ksi_1,ksi_2)\n",
    "S = mc.make_positive_definite(np.outer(epsilon_hat, epsilon_hat))\n",
    "init_omega_r = ro.r.matrix(init_omega, nrow=n, ncol=n)\n",
    "S_r = ro.r.matrix(S, nrow=n, ncol=n)\n",
    "Lambda_r = ro.r.matrix(Lambda, nrow=n, ncol=n)\n",
    "spcov_result = spcov.spcov(\n",
    "init_omega_r,\n",
    "S_r,\n",
    "Lambda_r,\n",
    "step_size=0.1,\n",
    "nesterov = True,\n",
    "n_outer_steps = 100,\n",
    "n_inner_steps = 100,\n",
    "tol_outer = 1e-04,\n",
    "thr_inner = 0.01,\n",
    "backtracking = 0.2,\n",
    "trace = 0\n",
    ")\n",
    "\n",
    "omega_hat_spcov = spcov_result[1]\n",
    "\n",
    "# Step 10: Construct the t-statistics for beta_hat\n",
    "t_stat_robust = beta_hat / np.sqrt(np.diag(sigma_hat_robust))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the R context for each thread or process\n",
    "def initialize_r_context():\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects.packages import importr\n",
    "    import rpy2.robjects.numpy2ri\n",
    "    \n",
    "    # Activate numpy2ri conversion within the local R context\n",
    "    rpy2.robjects.numpy2ri.activate()    \n",
    "    spcov = importr(\"spcov\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(i):\n",
    "    # Initialize R context for this thread or process\n",
    "    initialize_r_context()\n",
    "    print(f\"Iteration {i + 1} started...\")\n",
    "    try: \n",
    "        # Step 1: Generate x variables\n",
    "        x = np.random.normal(mu_x, sigma_x, (n, number_of_variables))\n",
    "\n",
    "        # Step 2: Generate three fixed-effect variables\n",
    "        fixed_effect_1 = np.random.normal(-2, 1, (N1, 1))\n",
    "        fixed_effect_2 = np.random.normal(3, 1, (N2, 1))\n",
    "        fixed_effect_3 = np.random.normal(1, 1, (T, 1))\n",
    "\n",
    "        # Step 3: Repeat the fixed-effect variables to match the desired dimensions\n",
    "        fixed_effect_1 = np.repeat(fixed_effect_1, N2 * T, axis=0)\n",
    "        fixed_effect_2 = np.tile(fixed_effect_2, (N1 * T, 1))\n",
    "        fixed_effect_3 = np.tile(fixed_effect_3, (N1 * N2, 1))\n",
    "\n",
    "        # Step 4: Stack the fixed-effect variables and combine x and fixed effects\n",
    "        fixed_effects_matrix = np.hstack((fixed_effect_1, fixed_effect_2, fixed_effect_3))\n",
    "        X = np.hstack((x, fixed_effects_matrix))\n",
    "\n",
    "        # Step 5: generate distrubances using the covariance matrix\n",
    "        omega = mc.generate_omega(case, mu_e, sigma_e, non_zero_prob, N1, N2, T, seed)\n",
    "        disturbances = mc.generate_disturbances(mu_e_vec, omega, n, t_dist_degree, lambda_parameter, mu_U, specification, seed)\n",
    "\n",
    "        # Step 6: Generate y using linear relationship: y = X * beta + FE + disturbances\n",
    "        y = np.dot(x, beta) + fixed_effects_matrix.sum(axis=1) + disturbances.flatten()\n",
    "\n",
    "        # Step 7: Transform X and y\n",
    "        x_tilde, y_tilde = mc.transform_xy(X, y,number_of_variables)\n",
    "        X = np.hstack((x_tilde, fixed_effects_matrix))\n",
    "        y = y_tilde\n",
    "\n",
    "        # Step 8: Estimate beta using OLS formula\n",
    "        X_with_intercept = np.hstack((np.ones((n, 1)), X))  # Adding intercept term\n",
    "        X_transpose = np.transpose(X_with_intercept)\n",
    "        X_transpose_X_inv = np.linalg.inv(np.dot(X_transpose, X_with_intercept))\n",
    "        beta_hat = np.dot(np.dot(X_transpose_X_inv, X_transpose), y)\n",
    "\n",
    "        # Step 9: Calculate the variance-covariance matrix of beta_hat\n",
    "\n",
    "        #OLS\n",
    "        epsilon_hat = y - np.dot(X_with_intercept, beta_hat)\n",
    "        omega_hat_ols = np.dot(epsilon_hat, epsilon_hat)/(n-number_of_variables-4)\n",
    "        sigma_hat_ols = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_ols), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "        #Robust\n",
    "        omega_hat_robust = np.outer(epsilon_hat, epsilon_hat)\n",
    "        omega_hat_robust = np.eye(omega_hat_robust.shape[0]) * omega_hat_robust\n",
    "        sigma_hat_robust = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_robust), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "        #spcov\n",
    "        init_omega = omega_hat_robust\n",
    "        Lambda = mc.generate_penalty_matrix(n, ksi_1,ksi_2)\n",
    "        S = mc.make_positive_definite(np.outer(epsilon_hat, epsilon_hat))\n",
    "        init_omega_r = ro.r.matrix(init_omega, nrow=n, ncol=n)\n",
    "        S_r = ro.r.matrix(S, nrow=n, ncol=n)\n",
    "        Lambda_r = ro.r.matrix(Lambda, nrow=n, ncol=n)\n",
    "        spcov_result = spcov.spcov(\n",
    "        init_omega_r,\n",
    "        S_r,\n",
    "        Lambda_r,\n",
    "        step_size=0.1,\n",
    "        nesterov = True,\n",
    "        n_outer_steps = 100,\n",
    "        n_inner_steps = 100,\n",
    "        tol_outer = 1e-04,\n",
    "        thr_inner = 0.01,\n",
    "        backtracking = 0.2,\n",
    "        trace = 0\n",
    "        )\n",
    "\n",
    "        omega_hat_spcov = spcov_result[1]\n",
    "        sigma_hat_spcov = np.dot(np.dot(np.dot(np.dot(X_transpose_X_inv,X_transpose),omega_hat_spcov), X_with_intercept),X_transpose_X_inv)\n",
    "\n",
    "        # Step 10: Construct the t-statistics for beta_hat\n",
    "        t_stat_ols = beta_hat / np.sqrt(np.diag(sigma_hat_ols))\n",
    "        t_stat_robust = beta_hat / np.sqrt(np.diag(sigma_hat_robust))\n",
    "        t_stat_spcov = beta_hat / np.sqrt(np.diag(sigma_hat_spcov))\n",
    "\n",
    "        print(f\"Iteration {i + 1} completed.\")\n",
    "        \n",
    "        return beta_hat, t_stat_ols, t_stat_robust, t_stat_spcov\n",
    "    finally:\n",
    "        # Close the local R context\n",
    "        ro.r(\"gc()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to store results\n",
    "all_beta_hat = []\n",
    "all_t_stat_ols = []\n",
    "all_t_stat_robust = []\n",
    "all_t_stat_spcov = []\n",
    "iteration = 0\n",
    "\n",
    "# Define loop parameters\n",
    "num_iterations = 20  # Number of iterations\n",
    "num_processes = mp.cpu_count()  # Number of processes to run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 started...\n",
      "Iteration 2 started...\n",
      "Iteration 7 started...\n",
      "Iteration 6 started...\n",
      "Iteration 10 started...\n",
      "Iteration 5 started...\n",
      "Iteration 8 started...\n",
      "Iteration 1 started...\n",
      "Iteration 9 started...\n",
      "Iteration 4 started...\n",
      "Iteration 4 completed.\n",
      "Iteration 10 completed.Iteration 6 completed.\n",
      "\n",
      "Iteration 1 completed.\n",
      "Iteration 3 completed.\n",
      "Iteration 9 completed.\n",
      "Iteration 5 completed.\n",
      "Iteration 8 completed.\n",
      "Iteration 2 completed.\n",
      "Iteration 7 completed.\n",
      "Iteration 11 started...\n",
      "Iteration 16 started...\n",
      "Iteration 15 started...\n",
      "Iteration 17 started...\n",
      "Iteration 14 started...\n",
      "Iteration 12 started...\n",
      "Iteration 18 started...\n",
      "Iteration 16 completed.\n",
      "Iteration 11 completed.\n",
      "Iteration 13 started...\n",
      "Iteration 17 completed.\n",
      "Iteration 14 completed.\n",
      "Iteration 20 started...\n",
      "Iteration 12 completed.\n",
      "Iteration 19 started...\n",
      "Iteration 18 completed.\n",
      "Iteration 15 completed.\n",
      "Iteration 13 completed.\n",
      "Iteration 20 completed.\n",
      "Iteration 19 completed.\n",
      "Average beta_hat: [-9.78623925e-16  1.91310763e+00 -2.53574018e-16 -4.37903107e-17\n",
      "  3.25004397e-16]\n",
      "Average t_stat_ols: [-1.25565091e-15  1.63315917e+01 -1.39978395e-15 -2.61687634e-16\n",
      "  1.19173526e-15]\n",
      "Average t_stat_robust: [-1.40324321e-15  1.66073624e+01 -1.39635902e-15 -2.85131921e-16\n",
      "  1.17770831e-15]\n",
      "Average t_stat_spcov: [-1.25907646e-15  1.51001699e+01 -1.27936912e-15 -2.55138241e-16\n",
      "  1.07933997e-15]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create a thread pool executor\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_processes) as executor:\n",
    "        # Use a list comprehension to submit tasks to the thread pool\n",
    "        futures = [executor.submit(run_iteration, i) for i in range(num_iterations)]\n",
    "        \n",
    "        # Retrieve results as they become available\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "    \n",
    "# Convert the results list to arrays\n",
    "all_beta_hat = np.array([result[0] for result in results])\n",
    "all_t_stat_ols = np.array([result[1] for result in results])\n",
    "all_t_stat_robust = np.array([result[2] for result in results])\n",
    "all_t_stat_spcov = np.array([result[3] for result in results])\n",
    "\n",
    "# Now you can analyze or summarize the results as needed\n",
    "average_beta_hat = np.mean(all_beta_hat, axis=0)\n",
    "average_t_stat_ols = np.mean(all_t_stat_ols, axis=0)\n",
    "average_t_stat_robust = np.mean(all_t_stat_robust, axis=0)\n",
    "average_t_stat_spcov = np.mean(all_t_stat_spcov, axis=0)\n",
    "\n",
    "print(\"Average beta_hat:\", average_beta_hat)\n",
    "print(\"Average t_stat_ols:\", average_t_stat_ols)\n",
    "print(\"Average t_stat_robust:\", average_t_stat_robust)\n",
    "print(\"Average t_stat_spcov:\", average_t_stat_spcov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
